[0m19:28:50.634760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39effd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3abe5350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39d657d0>]}


============================== 19:28:50.650870 | 087da984-82cd-483d-b771-d1151669b1f3 ==============================
[0m19:28:50.650870 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:28:50.652056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'profiles_dir': '.dbt/', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:28:50.653001 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /workspaces/flagstone-project/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m19:28:50.656216 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.10514246, "process_in_blocks": "82520", "process_kernel_time": 0.392456, "process_mem_max_rss": "91616", "process_out_blocks": "16", "process_user_time": 1.788871}
[0m19:28:50.656933 [debug] [MainThread]: Command `dbt run` failed at 19:28:50.656719 after 0.11 seconds
[0m19:28:50.657617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39f05a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39f06490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc39d6df10>]}
[0m19:28:50.658206 [debug] [MainThread]: Flushing usage events
[0m19:28:51.857164 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:29:10.806605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2917c1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2939d9dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2917c01d0>]}


============================== 19:29:10.810979 | fbdd51e5-9862-4c4f-b838-b89e7b83c15c ==============================
[0m19:29:10.810979 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:29:10.811868 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/workspaces/flagstone-project/logs', 'debug': 'False', 'profiles_dir': '.dbt/', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:29:11.859988 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:29:11.860898 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:29:11.861609 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:29:13.736454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa291d0d910>]}
[0m19:29:13.844631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa29160bbd0>]}
[0m19:29:13.845658 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:29:14.191211 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:29:16.387165 [warn ] [MainThread]: Databricks adapter: Exception while trying to save credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:29:16.587855 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m19:29:16.588762 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m19:29:16.589428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa262c51a10>]}
[0m19:29:18.952392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa262a38d50>]}
[0m19:29:19.059491 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:29:19.078851 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:29:19.284646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa262923950>]}
[0m19:29:19.285442 [info ] [MainThread]: Found 3 models, 3 sources, 606 macros
[0m19:29:19.285968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fbdd51e5-9862-4c4f-b838-b89e7b83c15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa261126090>]}
[0m19:29:19.288256 [info ] [MainThread]: 
[0m19:29:19.288849 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:29:19.289311 [info ] [MainThread]: 
[0m19:29:19.290249 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140335415179600, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6668, 140336269314944), compute-name=) - Creating connection
[0m19:29:19.290893 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:29:19.291591 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140335415179600, session-id=None, name=master, idle-time=1.0967254638671875e-05s, acquire-count=1, language=None, thread-identifier=(6668, 140336269314944), compute-name=) - Acquired connection on thread (6668, 140336269314944), using default compute resource
[0m19:29:19.313859 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140335415810448, session-id=None, name=list_retail_data, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6668, 140335388689984), compute-name=) - Creating connection
[0m19:29:19.315025 [debug] [ThreadPool]: Acquiring new databricks connection 'list_retail_data'
[0m19:29:19.315960 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140335415810448, session-id=None, name=list_retail_data, idle-time=1.2874603271484375e-05s, acquire-count=1, language=None, thread-identifier=(6668, 140335388689984), compute-name=) - Acquired connection on thread (6668, 140335388689984), using default compute resource
[0m19:29:19.317307 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140335415810448, session-id=None, name=list_retail_data, idle-time=0.0013728141784667969s, acquire-count=1, language=None, thread-identifier=(6668, 140335388689984), compute-name=) - Checking idleness
[0m19:29:19.318488 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140335415810448, session-id=None, name=list_retail_data, idle-time=0.00254058837890625s, acquire-count=1, language=None, thread-identifier=(6668, 140335388689984), compute-name=) - Retrieving connection
[0m19:29:19.319263 [debug] [ThreadPool]: Using databricks connection "list_retail_data"
[0m19:29:19.320011 [debug] [ThreadPool]: On list_retail_data: GetSchemas(database=retail_data, schema=None)
[0m19:29:19.320746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:29:19.957799 [error] [ThreadPool]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.
Error properties: attempt=1/5, bounded-retry-delay=None, elapsed-seconds=0.4399898052215576/900.0, error-message=, http-code=None, method=OpenSession, no-retry-reason=non-retryable error, original-exception=Received 403 - FORBIDDEN. Confirm your authentication credentials., query-id=None, session-id=None
[0m19:29:19.958974 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
GetSchemas(database=retail_data, schema=None)
: Database Error
  Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.
[0m19:29:19.960000 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140335415810448, session-id=None, name=list_retail_data, idle-time=9.5367431640625e-06s, acquire-count=0, language=None, thread-identifier=(6668, 140335388689984), compute-name=) - Released connection
[0m19:29:19.962181 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140335415179600, session-id=None, name=master, idle-time=1.8835067749023438e-05s, acquire-count=0, language=None, thread-identifier=(6668, 140336269314944), compute-name=) - Released connection
[0m19:29:19.963362 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:29:19.963965 [debug] [MainThread]: Connection 'list_retail_data' was properly closed.
[0m19:29:19.964614 [debug] [MainThread]: On list_retail_data: No close available on handle
[0m19:29:19.965099 [info ] [MainThread]: 
[0m19:29:19.965818 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.68 seconds (0.68s).
[0m19:29:19.967334 [error] [MainThread]: Encountered an error:
Database Error
  Database Error
    Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.
[0m19:29:19.969241 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.254638, "process_in_blocks": "199072", "process_kernel_time": 0.530493, "process_mem_max_rss": "241164", "process_out_blocks": "2680", "process_user_time": 7.06693}
[0m19:29:19.970014 [debug] [MainThread]: Command `dbt run` failed at 19:29:19.969827 after 9.26 seconds
[0m19:29:19.970629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2917ec690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2917ec8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa295319990>]}
[0m19:29:19.971406 [debug] [MainThread]: Flushing usage events
[0m19:29:21.019869 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:29:46.580191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc5bcf5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc5bcec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc5d71fd0>]}


============================== 19:29:46.587397 | dedec894-f0f6-4611-8395-3af8f08468dc ==============================
[0m19:29:46.587397 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:29:46.588482 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'debug': 'False', 'version_check': 'True', 'log_path': '/workspaces/flagstone-project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:29:47.430704 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:29:47.431507 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:29:47.432151 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:29:48.410871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dedec894-f0f6-4611-8395-3af8f08468dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f97265a90>]}
[0m19:29:48.507443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dedec894-f0f6-4611-8395-3af8f08468dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc6aff210>]}
[0m19:29:48.508483 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:29:48.753871 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:30:13.985063 [error] [MainThread]: Encountered an error:

[0m19:30:14.015675 [error] [MainThread]: Traceback (most recent call last):
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 327, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/cli/requires.py", line 351, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/parser/manifest.py", line 2058, in parse_manifest
    register_adapter(runtime_config, get_mp_context())
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/factory.py", line 203, in register_adapter
    FACTORY.register_adapter(config, mp_context, adapter_registered_log_level)
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/factory.py", line 118, in register_adapter
    adapter: Adapter = adapter_type(config, mp_context)  # type: ignore
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/databricks/impl.py", line 176, in __init__
    super().__init__(config, mp_context)
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/base/impl.py", line 289, in __init__
    self.connections = self.ConnectionManager(config, mp_context)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/databricks/connections.py", line 712, in __init__
    super().__init__(profile, mp_context)
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/databricks/connections.py", line 387, in __init__
    self.api_client = DatabricksApiClient.create(creds, 15 * 60)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/databricks/api_client.py", line 560, in create
    credentials_provider = credentials.authenticate(None)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/dbt/adapters/databricks/credentials.py", line 310, in authenticate
    provider = consent.launch_external_browser()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/site-packages/databricks/sdk/oauth.py", line 290, in launch_external_browser
    httpd.handle_request()
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/socketserver.py", line 295, in handle_request
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vscode/.pyenv/versions/3.11.11/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m19:30:14.024947 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 29.300236, "process_in_blocks": "304", "process_kernel_time": 0.340666, "process_mem_max_rss": "231596", "process_out_blocks": "40", "process_user_time": 4.211021}
[0m19:30:14.033298 [debug] [MainThread]: Command `dbt run` failed at 19:30:14.032728 after 29.31 seconds
[0m19:30:14.035589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc9a1d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f9ccbcd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc98b0f10>]}
[0m19:30:14.037383 [debug] [MainThread]: Flushing usage events
[0m19:30:15.306518 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:30:21.550321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec0650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec07d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec0350>]}


============================== 19:30:21.553863 | f974e7bd-611b-45c9-8aa3-3af0c97b5e0e ==============================
[0m19:30:21.553863 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:30:21.554662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/workspaces/flagstone-project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:30:21.681312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f974e7bd-611b-45c9-8aa3-3af0c97b5e0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffd25bd0>]}
[0m19:30:21.713668 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2245119, "process_in_blocks": "24", "process_kernel_time": 0.122489, "process_mem_max_rss": "93276", "process_out_blocks": "16", "process_user_time": 1.582942}
[0m19:30:21.714152 [debug] [MainThread]: Command `dbt clean` succeeded at 19:30:21.714022 after 0.23 seconds
[0m19:30:21.714512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec0990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec1b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79ffec0510>]}
[0m19:30:21.714935 [debug] [MainThread]: Flushing usage events
[0m19:30:23.006522 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:30:32.816753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d9456dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d9456910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d9457b10>]}


============================== 19:30:32.820286 | 44e707aa-fa21-4fbc-8326-4205c971cd6d ==============================
[0m19:30:32.820286 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:30:32.821008 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/workspaces/flagstone-project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:30:32.847651 [info ] [MainThread]: dbt version: 1.9.1
[0m19:30:32.849436 [info ] [MainThread]: python version: 3.11.11
[0m19:30:32.850268 [info ] [MainThread]: python path: /home/vscode/.pyenv/versions/3.11.11/bin/python3.11
[0m19:30:32.850831 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[0m19:30:33.499849 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:30:33.500473 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:30:33.501158 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:30:34.225559 [info ] [MainThread]: Using profiles dir at .dbt/
[0m19:30:34.226278 [info ] [MainThread]: Using profiles.yml file at .dbt/profiles.yml
[0m19:30:34.226954 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/flagstone-project/dbt_project.yml
[0m19:30:34.227364 [info ] [MainThread]: adapter type: databricks
[0m19:30:34.227796 [info ] [MainThread]: adapter version: 1.9.1
[0m19:30:34.393509 [info ] [MainThread]: Configuration:
[0m19:30:34.394729 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:30:34.395790 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:30:34.396734 [info ] [MainThread]: Required dependencies:
[0m19:30:34.397758 [debug] [MainThread]: Executing "git --help"
[0m19:30:34.401626 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:30:34.402826 [debug] [MainThread]: STDERR: "b''"
[0m19:30:34.403816 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:30:34.404782 [info ] [MainThread]: Connection:
[0m19:30:34.405873 [info ] [MainThread]:   host: adb-2822429466874508.8.azuredatabricks.net
[0m19:30:34.406775 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cb126c8f6c99e71d
[0m19:30:34.407827 [info ] [MainThread]:   catalog: shop_data
[0m19:30:34.408778 [info ] [MainThread]:   schema: sales_data
[0m19:30:34.410049 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:30:34.647702 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:30:36.602805 [warn ] [MainThread]: Databricks adapter: Exception while trying to save credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:30:36.753283 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140495539213328, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7648, 140496389217152), compute-name=) - Creating connection
[0m19:30:36.754407 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:30:36.755663 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140495539213328, session-id=None, name=debug, idle-time=1.1682510375976562e-05s, acquire-count=1, language=None, thread-identifier=(7648, 140496389217152), compute-name=) - Acquired connection on thread (7648, 140496389217152), using default compute resource
[0m19:30:36.756796 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140495539213328, session-id=None, name=debug, idle-time=0.001220703125s, acquire-count=1, language=None, thread-identifier=(7648, 140496389217152), compute-name=) - Checking idleness
[0m19:30:36.757709 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140495539213328, session-id=None, name=debug, idle-time=0.0020859241485595703s, acquire-count=1, language=None, thread-identifier=(7648, 140496389217152), compute-name=) - Retrieving connection
[0m19:30:36.758469 [debug] [MainThread]: Using databricks connection "debug"
[0m19:30:36.759213 [debug] [MainThread]: On debug: select 1 as id
[0m19:30:36.759717 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:30:37.354205 [error] [MainThread]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.
Error properties: attempt=1/5, bounded-retry-delay=None, elapsed-seconds=0.45258617401123047/900.0, error-message=, http-code=None, method=OpenSession, no-retry-reason=non-retryable error, original-exception=Received 403 - FORBIDDEN. Confirm your authentication credentials., query-id=None, session-id=None
[0m19:30:37.355634 [debug] [MainThread]: Databricks adapter: Exception while trying to execute query
select 1 as id
: Database Error
  Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.
[0m19:30:37.356469 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140495539213328, session-id=None, name=debug, idle-time=9.059906005859375e-06s, acquire-count=0, language=None, thread-identifier=(7648, 140496389217152), compute-name=) - Released connection
[0m19:30:37.357032 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m19:30:37.357725 [info ] [MainThread]: [31m1 check failed:[0m
[0m19:30:37.358425 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Database Error
    Error during request to server. Received 403 - FORBIDDEN. Confirm your authentication credentials.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m19:30:37.360099 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 4.603735, "process_in_blocks": "104", "process_kernel_time": 0.420634, "process_mem_max_rss": "232348", "process_out_blocks": "40", "process_user_time": 3.971575}
[0m19:30:37.361180 [debug] [MainThread]: Command `dbt debug` failed at 19:30:37.360847 after 4.60 seconds
[0m19:30:37.362189 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:30:37.362922 [debug] [MainThread]: On debug: No close available on handle
[0m19:30:37.363864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d96f5090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7aaa4b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7d945fe10>]}
[0m19:30:37.365256 [debug] [MainThread]: Flushing usage events
[0m19:30:38.504615 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:31:52.885605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297db606d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297df5be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297e051510>]}


============================== 19:31:52.889009 | 72508525-2b0e-4d9e-97dc-c0d8c24db7e4 ==============================
[0m19:31:52.889009 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:31:52.889716 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/workspaces/flagstone-project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:31:52.897595 [info ] [MainThread]: dbt version: 1.9.1
[0m19:31:52.898243 [info ] [MainThread]: python version: 3.11.11
[0m19:31:52.898781 [info ] [MainThread]: python path: /home/vscode/.pyenv/versions/3.11.11/bin/python3.11
[0m19:31:52.899319 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[0m19:31:53.567007 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:31:53.568429 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:31:53.569343 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:31:54.397040 [info ] [MainThread]: Using profiles dir at .dbt/
[0m19:31:54.397990 [info ] [MainThread]: Using profiles.yml file at .dbt/profiles.yml
[0m19:31:54.399074 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/flagstone-project/dbt_project.yml
[0m19:31:54.399658 [info ] [MainThread]: adapter type: databricks
[0m19:31:54.400209 [info ] [MainThread]: adapter version: 1.9.1
[0m19:31:54.573206 [info ] [MainThread]: Configuration:
[0m19:31:54.573880 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:31:54.574398 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:31:54.574844 [info ] [MainThread]: Required dependencies:
[0m19:31:54.575303 [debug] [MainThread]: Executing "git --help"
[0m19:31:54.578046 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:31:54.578618 [debug] [MainThread]: STDERR: "b''"
[0m19:31:54.579000 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:31:54.579494 [info ] [MainThread]: Connection:
[0m19:31:54.580003 [info ] [MainThread]:   host: adb-2822429466874508.8.azuredatabricks.net
[0m19:31:54.580426 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cb126c8f6c99e71d
[0m19:31:54.580781 [info ] [MainThread]:   catalog: shop_data
[0m19:31:54.581128 [info ] [MainThread]:   schema: sales_data
[0m19:31:54.581903 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:31:54.839766 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:31:56.665952 [warn ] [MainThread]: Databricks adapter: Exception while trying to save credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:31:56.818897 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Creating connection
[0m19:31:56.820181 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:31:56.821914 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=None, name=debug, idle-time=1.4543533325195312e-05s, acquire-count=1, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Acquired connection on thread (8131, 139816246659968), using default compute resource
[0m19:31:56.823016 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=None, name=debug, idle-time=0.0013566017150878906s, acquire-count=1, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Checking idleness
[0m19:31:56.823740 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=None, name=debug, idle-time=0.002122640609741211s, acquire-count=1, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Retrieving connection
[0m19:31:56.824219 [debug] [MainThread]: Using databricks connection "debug"
[0m19:31:56.824669 [debug] [MainThread]: On debug: select 1 as id
[0m19:31:56.825074 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:31:57.616248 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=01efc2f6-e66f-1c62-b270-30fcdfa274ca, name=debug, idle-time=1.2159347534179688e-05s, acquire-count=1, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Connection created
[0m19:31:57.617337 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f6-e66f-1c62-b270-30fcdfa274ca, command-id=Unknown) - Created cursor
[0m19:32:01.824802 [debug] [MainThread]: SQL status: OK in 5.000 seconds
[0m19:32:01.826483 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f6-e66f-1c62-b270-30fcdfa274ca, command-id=01efc2f6-e6b9-15de-8432-4fd9f3dba66e) - Closing cursor
[0m19:32:02.021908 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=139815395626512, session-id=01efc2f6-e66f-1c62-b270-30fcdfa274ca, name=debug, idle-time=1.9788742065429688e-05s, acquire-count=0, language=None, thread-identifier=(8131, 139816246659968), compute-name=) - Released connection
[0m19:32:02.022774 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m19:32:02.023550 [info ] [MainThread]: [32mAll checks passed![0m
[0m19:32:02.025991 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 10.865464, "process_in_blocks": "2744", "process_kernel_time": 0.444168, "process_mem_max_rss": "232672", "process_out_blocks": "56", "process_user_time": 4.233772}
[0m19:32:02.027022 [debug] [MainThread]: Command `dbt debug` succeeded at 19:32:02.026765 after 10.87 seconds
[0m19:32:02.027848 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:32:02.028504 [debug] [MainThread]: On debug: Close
[0m19:32:02.029123 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f6-e66f-1c62-b270-30fcdfa274ca) - Closing connection
[0m19:32:02.110330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297db61a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f297d9c7ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f294f246550>]}
[0m19:32:02.111261 [debug] [MainThread]: Flushing usage events
[0m19:32:03.405385 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:32:11.840990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a54f8a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a54f8850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a54f8350>]}


============================== 19:32:11.844722 | 0f8d2dc5-a258-49c4-8dea-614aba19fd44 ==============================
[0m19:32:11.844722 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:32:11.845392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/workspaces/flagstone-project/logs', 'profiles_dir': '.dbt/', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:32:12.475527 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:32:12.476421 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:32:12.477533 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:32:13.322300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff476b1aed0>]}
[0m19:32:13.388143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a553fe10>]}
[0m19:32:13.389083 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:32:13.598629 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:32:15.279939 [warn ] [MainThread]: Databricks adapter: Exception while trying to save credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:32:15.469127 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m19:32:15.470165 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m19:32:15.470867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff476e23bd0>]}
[0m19:32:17.574539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4766c90d0>]}
[0m19:32:17.687215 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:32:17.689198 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:32:17.827227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff476658950>]}
[0m19:32:17.828763 [info ] [MainThread]: Found 3 models, 3 sources, 606 macros
[0m19:32:17.829940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4766c3ed0>]}
[0m19:32:17.833434 [info ] [MainThread]: 
[0m19:32:17.834226 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:32:17.834923 [info ] [MainThread]: 
[0m19:32:17.836076 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Creating connection
[0m19:32:17.836813 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:32:17.837503 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=1.3113021850585938e-05s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Acquired connection on thread (8451, 140688789367680), using default compute resource
[0m19:32:17.851147 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=None, name=list_retail_data, idle-time=0s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Creating connection
[0m19:32:17.852229 [debug] [ThreadPool]: Acquiring new databricks connection 'list_retail_data'
[0m19:32:17.852871 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=None, name=list_retail_data, idle-time=7.3909759521484375e-06s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Acquired connection on thread (8451, 140687906625088), using default compute resource
[0m19:32:17.853548 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=None, name=list_retail_data, idle-time=0.0007507801055908203s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:17.854562 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=None, name=list_retail_data, idle-time=0.0017321109771728516s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:17.855299 [debug] [ThreadPool]: Using databricks connection "list_retail_data"
[0m19:32:17.855859 [debug] [ThreadPool]: On list_retail_data: GetSchemas(database=retail_data, schema=None)
[0m19:32:17.856630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:32:18.296349 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data, idle-time=9.059906005859375e-06s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Connection created
[0m19:32:18.297353 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=Unknown) - Created cursor
[0m19:32:19.387518 [debug] [ThreadPool]: SQL status: OK in 1.530 seconds
[0m19:32:19.389139 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=01efc2f6-f35b-188f-bb1f-1cb92fc923fc) - Closing cursor
[0m19:32:19.389853 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data, idle-time=7.3909759521484375e-06s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:19.392346 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data, idle-time=0.0024781227111816406s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:19.393219 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_retail_data, now list_retail_data_sales_data)
[0m19:32:19.393666 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.003877878189086914s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Reusing connection previously named list_retail_data
[0m19:32:19.394065 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.004283905029296875s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Acquired connection on thread (8451, 140687906625088), using default compute resource
[0m19:32:19.404096 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.01425933837890625s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:19.404619 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.014826774597167969s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:19.405547 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.015221357345581055s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:19.406988 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.017081499099731445s, acquire-count=1, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:19.407572 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:32:19.407931 [debug] [ThreadPool]: Using databricks connection "list_retail_data_sales_data"
[0m19:32:19.408626 [debug] [ThreadPool]: On list_retail_data_sales_data: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "connection_name": "list_retail_data_sales_data"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'retail_data'
      and table_schema = 'sales_data'
    
  
[0m19:32:19.409332 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=Unknown) - Created cursor
[0m19:32:20.810564 [debug] [ThreadPool]: SQL status: OK in 1.400 seconds
[0m19:32:20.830963 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=01efc2f6-f3fb-19ad-be1f-3f1ce97ac6c8) - Closing cursor
[0m19:32:20.832723 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=5.9604644775390625e-06s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:20.836037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff474daffd0>]}
[0m19:32:20.836980 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=2.9995269775390625s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Checking idleness
[0m19:32:20.837623 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=3.0001449584960938s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Retrieving connection
[0m19:32:20.838148 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=3.0007176399230957s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Checking idleness
[0m19:32:20.838669 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=3.0012409687042236s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Retrieving connection
[0m19:32:20.839092 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:32:20.839509 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:32:20.840005 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Released connection
[0m19:32:20.843685 [debug] [Thread-1 (]: Began running node model.databricks.stg_customers
[0m19:32:20.844672 [info ] [Thread-1 (]: 1 of 3 START sql table model retail_data.sales_data.stg_customers .............. [RUN]
[0m19:32:20.845537 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=list_retail_data_sales_data, idle-time=0.012826919555664062s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:20.845981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_retail_data_sales_data, now model.databricks.stg_customers)
[0m19:32:20.846403 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=0.013766288757324219s, acquire-count=0, language=None, thread-identifier=(8451, 140687906625088), compute-name=) - Reusing connection previously named list_retail_data_sales_data
[0m19:32:20.846867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=0.014226436614990234s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Acquired connection on thread (8451, 140687906625088), using default compute resource for model '`retail_data`.`sales_data`.`stg_customers`'
[0m19:32:20.847247 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_customers
[0m19:32:20.857195 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_customers"
[0m19:32:20.861217 [debug] [Thread-1 (]: Began executing node model.databricks.stg_customers
[0m19:32:20.877470 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:32:20.944643 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_customers"
[0m19:32:20.946440 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=0.1137399673461914s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:20.946957 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=0.11429691314697266s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:20.947280 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_customers"
[0m19:32:20.947702 [debug] [Thread-1 (]: On model.databricks.stg_customers: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_customers"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_customers`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS customer_id,
    first_name,
    last_name
FROM 
    `shop_data`.`sales_data`.`customers`
  
[0m19:32:20.948155 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=Unknown) - Created cursor
[0m19:32:28.909052 [debug] [Thread-1 (]: SQL status: OK in 7.960 seconds
[0m19:32:28.911737 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=01efc2f6-f4da-11ac-b360-a8873b9f5a4c) - Closing cursor
[0m19:32:29.071678 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=2.0503997802734375e-05s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:29.072338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:29.074893 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a3c5e1d0>]}
[0m19:32:29.075600 [info ] [Thread-1 (]: 1 of 3 OK created sql table model retail_data.sales_data.stg_customers ......... [[32mOK[0m in 8.23s]
[0m19:32:29.076312 [debug] [Thread-1 (]: Finished running node model.databricks.stg_customers
[0m19:32:29.076746 [debug] [Thread-1 (]: Began running node model.databricks.stg_orders
[0m19:32:29.077338 [info ] [Thread-1 (]: 2 of 3 START sql table model retail_data.sales_data.stg_orders ................. [RUN]
[0m19:32:29.078008 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_customers, idle-time=0.005650520324707031s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:29.078370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_customers, now model.databricks.stg_orders)
[0m19:32:29.078782 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=0.006458282470703125s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Reusing connection previously named model.databricks.stg_customers
[0m19:32:29.079190 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=0.006868839263916016s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Acquired connection on thread (8451, 140687906625088), using default compute resource for model '`retail_data`.`sales_data`.`stg_orders`'
[0m19:32:29.079605 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_orders
[0m19:32:27.441035 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_orders"
[0m19:32:27.442540 [debug] [Thread-1 (]: Began executing node model.databricks.stg_orders
[0m19:32:27.445906 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:32:27.448412 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_orders"
[0m19:32:27.449194 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=-1.6232118606567383s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:27.449762 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=-1.6226513385772705s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:27.450116 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_orders"
[0m19:32:27.450536 [debug] [Thread-1 (]: On model.databricks.stg_orders: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_orders"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_orders`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS order_id,
    user_id AS customer_id,
    order_date,
    status
FROM 
    `shop_data`.`sales_data`.`orders`
  
[0m19:32:27.450983 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=Unknown) - Created cursor
[0m19:32:31.513075 [debug] [Thread-1 (]: SQL status: OK in 4.060 seconds
[0m19:32:31.515149 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=01efc2f6-f974-1f47-b2dd-be331bf9ce0c) - Closing cursor
[0m19:32:31.519091 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:31.520246 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:31.520807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4773f0f50>]}
[0m19:32:31.521568 [info ] [Thread-1 (]: 2 of 3 OK created sql table model retail_data.sales_data.stg_orders ............ [[32mOK[0m in 2.44s]
[0m19:32:31.522275 [debug] [Thread-1 (]: Finished running node model.databricks.stg_orders
[0m19:32:31.522760 [debug] [Thread-1 (]: Began running node model.databricks.stg_payments
[0m19:32:31.523579 [info ] [Thread-1 (]: 3 of 3 START sql table model retail_data.sales_data.stg_payments ............... [RUN]
[0m19:32:31.524317 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_orders, idle-time=0.0041048526763916016s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:31.524713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_orders, now model.databricks.stg_payments)
[0m19:32:31.525092 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=0.004903078079223633s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Reusing connection previously named model.databricks.stg_orders
[0m19:32:31.525484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=0.005282163619995117s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Acquired connection on thread (8451, 140687906625088), using default compute resource for model '`retail_data`.`sales_data`.`stg_payments`'
[0m19:32:31.525933 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_payments
[0m19:32:31.529256 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_payments"
[0m19:32:31.530088 [debug] [Thread-1 (]: Began executing node model.databricks.stg_payments
[0m19:32:31.533248 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:32:31.543888 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_payments"
[0m19:32:31.545232 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=0.024927854537963867s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Checking idleness
[0m19:32:31.545685 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=0.025490760803222656s, acquire-count=1, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Retrieving connection
[0m19:32:31.546016 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_payments"
[0m19:32:31.546416 [debug] [Thread-1 (]: On model.databricks.stg_payments: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_payments"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_payments`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS payment_id,
    order_id,
    payment_method,
    amount
FROM 
    `shop_data`.`sales_data`.`payments`
  
[0m19:32:31.547066 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=Unknown) - Created cursor
[0m19:32:34.786970 [debug] [Thread-1 (]: SQL status: OK in 3.240 seconds
[0m19:32:34.789151 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, command-id=01efc2f6-fbc6-16d6-b3e4-0e93556f64c0) - Closing cursor
[0m19:32:34.794749 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:34.796883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140687935906896, session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8, name=model.databricks.stg_payments, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(8451, 140687906625088), compute-name=) - Released connection
[0m19:32:34.798984 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f8d2dc5-a258-49c4-8dea-614aba19fd44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff47692dd90>]}
[0m19:32:34.801211 [info ] [Thread-1 (]: 3 of 3 OK created sql table model retail_data.sales_data.stg_payments .......... [[32mOK[0m in 3.27s]
[0m19:32:34.803483 [debug] [Thread-1 (]: Finished running node model.databricks.stg_payments
[0m19:32:34.810628 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=13.969849824905396s, acquire-count=0, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Checking idleness
[0m19:32:34.812363 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=13.972145795822144s, acquire-count=0, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Reusing connection previously named master
[0m19:32:34.813769 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=13.973606586456299s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Acquired connection on thread (8451, 140688789367680), using default compute resource
[0m19:32:34.815176 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=13.975051879882812s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Checking idleness
[0m19:32:34.816528 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=None, name=master, idle-time=13.976404666900635s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Retrieving connection
[0m19:32:34.817694 [debug] [MainThread]: On master: ROLLBACK
[0m19:32:34.818811 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:32:35.169062 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=01efc2f6-fdc7-1245-bfbe-830a8dea24c0, name=master, idle-time=8.344650268554688e-06s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Connection created
[0m19:32:35.170088 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:32:35.170552 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=01efc2f6-fdc7-1245-bfbe-830a8dea24c0, name=master, idle-time=0.0017399787902832031s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Checking idleness
[0m19:32:35.170945 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=01efc2f6-fdc7-1245-bfbe-830a8dea24c0, name=master, idle-time=0.002142667770385742s, acquire-count=1, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Retrieving connection
[0m19:32:35.171309 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:32:35.171821 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:32:35.172321 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140687908102096, session-id=01efc2f6-fdc7-1245-bfbe-830a8dea24c0, name=master, idle-time=3.337860107421875e-06s, acquire-count=0, language=None, thread-identifier=(8451, 140688789367680), compute-name=) - Released connection
[0m19:32:35.172950 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:32:35.173588 [debug] [MainThread]: On master: ROLLBACK
[0m19:32:35.174077 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:32:35.174498 [debug] [MainThread]: On master: Close
[0m19:32:35.174932 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f6-fdc7-1245-bfbe-830a8dea24c0) - Closing connection
[0m19:32:35.243653 [debug] [MainThread]: Connection 'model.databricks.stg_payments' was properly closed.
[0m19:32:35.244690 [debug] [MainThread]: On model.databricks.stg_payments: ROLLBACK
[0m19:32:35.245773 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:32:35.246519 [debug] [MainThread]: On model.databricks.stg_payments: Close
[0m19:32:35.247304 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f6-f34a-18dd-bc67-bd89fe1668d8) - Closing connection
[0m19:32:35.319913 [info ] [MainThread]: 
[0m19:32:35.321913 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 17.48 seconds (17.48s).
[0m19:32:35.324134 [debug] [MainThread]: Command end result
[0m19:32:35.379881 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:32:35.382093 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:32:35.389888 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspaces/flagstone-project/target/run_results.json
[0m19:32:35.390401 [info ] [MainThread]: 
[0m19:32:35.390937 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:32:35.391346 [info ] [MainThread]: 
[0m19:32:35.391761 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m19:32:35.393389 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 25.250273, "process_in_blocks": "1848", "process_kernel_time": 0.514786, "process_mem_max_rss": "246136", "process_out_blocks": "4096", "process_user_time": 6.482496}
[0m19:32:35.393968 [debug] [MainThread]: Command `dbt run` succeeded at 19:32:35.393833 after 25.25 seconds
[0m19:32:35.394493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a58fc510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a58f3e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4a9070f50>]}
[0m19:32:35.394956 [debug] [MainThread]: Flushing usage events
[0m19:32:36.619636 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:32:52.808144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33a112d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33a0b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33a0bc90>]}


============================== 19:32:52.813043 | 443edca1-749e-4429-9685-0d1119e0a9be ==============================
[0m19:32:52.813043 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:32:52.814046 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '.dbt/', 'log_path': '/workspaces/flagstone-project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m19:32:53.591158 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:32:53.592581 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:32:53.593442 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:32:54.575027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce051efe50>]}
[0m19:32:54.659703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33888050>]}
[0m19:32:54.660923 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:32:54.883352 [warn ] [MainThread]: Databricks adapter: Exception while trying to load credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:32:56.604208 [warn ] [MainThread]: Databricks adapter: Exception while trying to save credentials: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.
[0m19:32:56.769678 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m19:32:56.937346 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:32:56.937994 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:32:57.010291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce04e37210>]}
[0m19:32:57.141336 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:32:57.144401 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:32:57.161624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce04b76650>]}
[0m19:32:57.162691 [info ] [MainThread]: Found 3 models, 3 sources, 606 macros
[0m19:32:57.163384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce2f7c2e90>]}
[0m19:32:57.166050 [info ] [MainThread]: 
[0m19:32:57.166729 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:32:57.167319 [info ] [MainThread]: 
[0m19:32:57.168384 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Creating connection
[0m19:32:57.168922 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:32:57.169723 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.106231689453125e-06s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Acquired connection on thread (8952, 140523673508736), using default compute resource
[0m19:32:57.189779 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=None, name=list_retail_data, idle-time=0s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Creating connection
[0m19:32:57.191242 [debug] [ThreadPool]: Acquiring new databricks connection 'list_retail_data'
[0m19:32:57.191927 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=None, name=list_retail_data, idle-time=1.1205673217773438e-05s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Acquired connection on thread (8952, 140522819098176), using default compute resource
[0m19:32:57.192591 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=None, name=list_retail_data, idle-time=0.0007264614105224609s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:57.193373 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=None, name=list_retail_data, idle-time=0.0014996528625488281s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:32:57.194052 [debug] [ThreadPool]: Using databricks connection "list_retail_data"
[0m19:32:57.194749 [debug] [ThreadPool]: On list_retail_data: GetSchemas(database=retail_data, schema=None)
[0m19:32:57.195416 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:32:57.522006 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data, idle-time=4.673004150390625e-05s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Connection created
[0m19:32:57.522947 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=Unknown) - Created cursor
[0m19:32:58.114741 [debug] [ThreadPool]: SQL status: OK in 0.920 seconds
[0m19:32:58.117170 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=01efc2f7-0a78-18b7-b22a-7f3d9551850d) - Closing cursor
[0m19:32:58.117978 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data, idle-time=1.1205673217773438e-05s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:32:58.120429 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data, idle-time=0.002423524856567383s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:58.121292 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_retail_data, now list_retail_data_sales_data)
[0m19:32:58.121964 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.003987312316894531s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Reusing connection previously named list_retail_data
[0m19:32:58.122603 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.0046329498291015625s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Acquired connection on thread (8952, 140522819098176), using default compute resource
[0m19:32:58.141541 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.023514747619628906s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:58.143300 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.025186777114868164s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:32:58.144388 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.026378154754638672s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:58.145113 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.0270841121673584s, acquire-count=1, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:32:58.145736 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:32:58.146124 [debug] [ThreadPool]: Using databricks connection "list_retail_data_sales_data"
[0m19:32:58.146570 [debug] [ThreadPool]: On list_retail_data_sales_data: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "connection_name": "list_retail_data_sales_data"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'retail_data'
      and table_schema = 'sales_data'
    
  
[0m19:32:58.147039 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=Unknown) - Created cursor
[0m19:32:58.548788 [debug] [ThreadPool]: SQL status: OK in 0.400 seconds
[0m19:32:58.558767 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=01efc2f7-0ad2-16b5-a820-b81fa350b3d7) - Closing cursor
[0m19:32:58.560130 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=5.4836273193359375e-06s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:32:58.562858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce35c76cd0>]}
[0m19:32:58.564161 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=1.3944828510284424s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Checking idleness
[0m19:32:58.564664 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=1.3950319290161133s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Retrieving connection
[0m19:32:58.565092 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=1.395519495010376s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Checking idleness
[0m19:32:58.565499 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=1.3959271907806396s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Retrieving connection
[0m19:32:58.565885 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:32:58.566196 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:32:58.566605 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=3.5762786865234375e-06s, acquire-count=0, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Released connection
[0m19:32:58.569638 [debug] [Thread-1 (]: Began running node model.databricks.stg_customers
[0m19:32:58.570321 [info ] [Thread-1 (]: 1 of 3 START sql table model retail_data.sales_data.stg_customers .............. [RUN]
[0m19:32:58.571043 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=list_retail_data_sales_data, idle-time=0.010903120040893555s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:58.571424 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_retail_data_sales_data, now model.databricks.stg_customers)
[0m19:32:58.571970 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=0.011838674545288086s, acquire-count=0, language=None, thread-identifier=(8952, 140522819098176), compute-name=) - Reusing connection previously named list_retail_data_sales_data
[0m19:32:58.572597 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=0.012439489364624023s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Acquired connection on thread (8952, 140522819098176), using default compute resource for model '`retail_data`.`sales_data`.`stg_customers`'
[0m19:32:58.573008 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_customers
[0m19:32:58.583728 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_customers"
[0m19:32:58.585085 [debug] [Thread-1 (]: Began executing node model.databricks.stg_customers
[0m19:32:58.609410 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:32:58.697063 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_customers"
[0m19:32:58.698578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=0.13825750350952148s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:32:58.699635 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=0.13936352729797363s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:32:58.700222 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_customers"
[0m19:32:58.700865 [debug] [Thread-1 (]: On model.databricks.stg_customers: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_customers"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_customers`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS customer_id,
    first_name,
    last_name
FROM 
    `shop_data`.`sales_data`.`customers`
  
[0m19:32:58.704171 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=Unknown) - Created cursor
[0m19:33:00.377653 [debug] [Thread-1 (]: SQL status: OK in 1.680 seconds
[0m19:33:00.382082 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=01efc2f7-0b26-109b-a162-cb23c6d9cefc) - Closing cursor
[0m19:33:00.441220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=2.09808349609375e-05s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:00.442327 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=6.9141387939453125e-06s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:00.444812 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce04c927d0>]}
[0m19:33:00.445995 [info ] [Thread-1 (]: 1 of 3 OK created sql table model retail_data.sales_data.stg_customers ......... [[32mOK[0m in 1.87s]
[0m19:33:00.447428 [debug] [Thread-1 (]: Finished running node model.databricks.stg_customers
[0m19:33:00.448529 [debug] [Thread-1 (]: Began running node model.databricks.stg_orders
[0m19:33:00.450288 [info ] [Thread-1 (]: 2 of 3 START sql table model retail_data.sales_data.stg_orders ................. [RUN]
[0m19:33:00.452192 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_customers, idle-time=0.009614229202270508s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:33:00.453489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_customers, now model.databricks.stg_orders)
[0m19:33:00.454674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=0.012135028839111328s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Reusing connection previously named model.databricks.stg_customers
[0m19:33:00.456160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=0.0134735107421875s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Acquired connection on thread (8952, 140522819098176), using default compute resource for model '`retail_data`.`sales_data`.`stg_orders`'
[0m19:33:00.457706 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_orders
[0m19:33:00.464179 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_orders"
[0m19:33:00.465439 [debug] [Thread-1 (]: Began executing node model.databricks.stg_orders
[0m19:33:00.470085 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:33:00.480727 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_orders"
[0m19:33:00.483514 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=0.04072070121765137s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:33:00.485367 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=0.04260826110839844s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:33:00.486886 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_orders"
[0m19:33:00.488331 [debug] [Thread-1 (]: On model.databricks.stg_orders: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_orders"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_orders`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS order_id,
    user_id AS customer_id,
    order_date,
    status
FROM 
    `shop_data`.`sales_data`.`orders`
  
[0m19:33:00.490973 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=Unknown) - Created cursor
[0m19:33:03.977943 [debug] [Thread-1 (]: SQL status: OK in 3.490 seconds
[0m19:33:03.979245 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=01efc2f7-0d15-13aa-aecd-4c0de9c7577e) - Closing cursor
[0m19:33:03.981637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:03.982204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=3.814697265625e-06s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:03.982706 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce04282a50>]}
[0m19:33:03.983423 [info ] [Thread-1 (]: 2 of 3 OK created sql table model retail_data.sales_data.stg_orders ............ [[32mOK[0m in 3.53s]
[0m19:33:03.984246 [debug] [Thread-1 (]: Finished running node model.databricks.stg_orders
[0m19:33:03.984813 [debug] [Thread-1 (]: Began running node model.databricks.stg_payments
[0m19:33:03.985958 [info ] [Thread-1 (]: 3 of 3 START sql table model retail_data.sales_data.stg_payments ............... [RUN]
[0m19:33:03.986912 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_orders, idle-time=0.0046694278717041016s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:33:03.987389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_orders, now model.databricks.stg_payments)
[0m19:33:03.988134 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=0.00577855110168457s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Reusing connection previously named model.databricks.stg_orders
[0m19:33:03.988780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=0.0065593719482421875s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Acquired connection on thread (8952, 140522819098176), using default compute resource for model '`retail_data`.`sales_data`.`stg_payments`'
[0m19:33:03.989154 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_payments
[0m19:33:03.993465 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_payments"
[0m19:33:03.994801 [debug] [Thread-1 (]: Began executing node model.databricks.stg_payments
[0m19:33:03.998847 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:33:04.001985 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_payments"
[0m19:33:04.003112 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=0.020785808563232422s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Checking idleness
[0m19:33:04.003789 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=0.021530866622924805s, acquire-count=1, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Retrieving connection
[0m19:33:04.004236 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_payments"
[0m19:33:04.004808 [debug] [Thread-1 (]: On model.databricks.stg_payments: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_payments"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_payments`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS payment_id,
    order_id,
    payment_method,
    amount
FROM 
    `shop_data`.`sales_data`.`payments`
  
[0m19:33:04.005373 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=Unknown) - Created cursor
[0m19:33:06.698444 [debug] [Thread-1 (]: SQL status: OK in 2.690 seconds
[0m19:33:06.700570 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, command-id=01efc2f7-0f11-1bd0-a3a9-a44de1ec197a) - Closing cursor
[0m19:33:06.703858 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:06.704852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140522819112784, session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23, name=model.databricks.stg_payments, idle-time=6.67572021484375e-06s, acquire-count=0, language=sql, thread-identifier=(8952, 140522819098176), compute-name=) - Released connection
[0m19:33:06.705756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '443edca1-749e-4429-9685-0d1119e0a9be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce04293290>]}
[0m19:33:06.706934 [info ] [Thread-1 (]: 3 of 3 OK created sql table model retail_data.sales_data.stg_payments .......... [[32mOK[0m in 2.72s]
[0m19:33:06.708342 [debug] [Thread-1 (]: Finished running node model.databricks.stg_payments
[0m19:33:06.714021 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.147051572799683s, acquire-count=0, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Checking idleness
[0m19:33:06.715536 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.148736953735352s, acquire-count=0, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Reusing connection previously named master
[0m19:33:06.716482 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.149798154830933s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Acquired connection on thread (8952, 140523673508736), using default compute resource
[0m19:33:06.718365 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.151483297348022s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Checking idleness
[0m19:33:06.719564 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=None, name=master, idle-time=8.152736186981201s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Retrieving connection
[0m19:33:06.720465 [debug] [MainThread]: On master: ROLLBACK
[0m19:33:06.721146 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:33:07.074579 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=01efc2f7-10bf-195e-9966-2b0c14871139, name=master, idle-time=1.239776611328125e-05s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Connection created
[0m19:33:07.075716 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:33:07.076771 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=01efc2f7-10bf-195e-9966-2b0c14871139, name=master, idle-time=0.0023763179779052734s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Checking idleness
[0m19:33:07.077378 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=01efc2f7-10bf-195e-9966-2b0c14871139, name=master, idle-time=0.0030059814453125s, acquire-count=1, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Retrieving connection
[0m19:33:07.078021 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:33:07.078637 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:33:07.079359 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140522819121360, session-id=01efc2f7-10bf-195e-9966-2b0c14871139, name=master, idle-time=4.5299530029296875e-06s, acquire-count=0, language=None, thread-identifier=(8952, 140523673508736), compute-name=) - Released connection
[0m19:33:07.080102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:33:07.080744 [debug] [MainThread]: On master: ROLLBACK
[0m19:33:07.081453 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:33:07.081962 [debug] [MainThread]: On master: Close
[0m19:33:07.082720 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-10bf-195e-9966-2b0c14871139) - Closing connection
[0m19:33:07.166655 [debug] [MainThread]: Connection 'model.databricks.stg_payments' was properly closed.
[0m19:33:07.167748 [debug] [MainThread]: On model.databricks.stg_payments: ROLLBACK
[0m19:33:07.168449 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:33:07.169128 [debug] [MainThread]: On model.databricks.stg_payments: Close
[0m19:33:07.169800 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-0a6c-1d5b-a94f-a4965c496f23) - Closing connection
[0m19:33:07.252220 [info ] [MainThread]: 
[0m19:33:07.253299 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 10.08 seconds (10.08s).
[0m19:33:07.254711 [debug] [MainThread]: Command end result
[0m19:33:07.297712 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:33:07.302861 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:33:07.323143 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspaces/flagstone-project/target/run_results.json
[0m19:33:07.324445 [info ] [MainThread]: 
[0m19:33:07.325811 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:33:07.326916 [info ] [MainThread]: 
[0m19:33:07.327793 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m19:33:07.330241 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.258356, "process_in_blocks": "0", "process_kernel_time": 0.487964, "process_mem_max_rss": "241588", "process_out_blocks": "2760", "process_user_time": 5.434584}
[0m19:33:07.331177 [debug] [MainThread]: Command `dbt run` succeeded at 19:33:07.330968 after 16.26 seconds
[0m19:33:07.332224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33a747d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33a75310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce33e10750>]}
[0m19:33:07.333287 [debug] [MainThread]: Flushing usage events
[0m19:33:08.313536 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:34:24.003640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e3d49d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e3d4aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e3ee7a10>]}


============================== 19:34:24.008372 | 50b95575-b838-4475-ad9e-2f8a4687ed49 ==============================
[0m19:34:24.008372 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:34:24.009380 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'debug': 'False', 'version_check': 'True', 'log_path': '/workspaces/flagstone-project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:34:24.025879 [info ] [MainThread]: dbt version: 1.9.1
[0m19:34:24.026825 [info ] [MainThread]: python version: 3.11.11
[0m19:34:24.027611 [info ] [MainThread]: python path: /home/vscode/.pyenv/versions/3.11.11/bin/python3.11
[0m19:34:24.028191 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[0m19:34:24.835457 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:34:24.836337 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:34:24.837011 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:34:25.631287 [info ] [MainThread]: Using profiles dir at .dbt/
[0m19:34:25.631969 [info ] [MainThread]: Using profiles.yml file at .dbt/profiles.yml
[0m19:34:25.632646 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/flagstone-project/dbt_project.yml
[0m19:34:25.633305 [info ] [MainThread]: adapter type: databricks
[0m19:34:25.633895 [info ] [MainThread]: adapter version: 1.9.1
[0m19:34:25.770610 [info ] [MainThread]: Configuration:
[0m19:34:25.771229 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:34:25.771655 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:34:25.772054 [info ] [MainThread]: Required dependencies:
[0m19:34:25.772456 [debug] [MainThread]: Executing "git --help"
[0m19:34:25.774798 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:34:25.775831 [debug] [MainThread]: STDERR: "b''"
[0m19:34:25.776312 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:34:25.777170 [info ] [MainThread]: Connection:
[0m19:34:25.777938 [info ] [MainThread]:   host: adb-2822429466874508.8.azuredatabricks.net
[0m19:34:25.778687 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cb126c8f6c99e71d
[0m19:34:25.780137 [info ] [MainThread]:   catalog: shop_data
[0m19:34:25.781161 [info ] [MainThread]:   schema: sales_data
[0m19:34:25.782219 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:34:27.791279 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Creating connection
[0m19:34:27.791875 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:34:27.792504 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=None, name=debug, idle-time=7.152557373046875e-06s, acquire-count=1, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Acquired connection on thread (9965, 140702724918144), using default compute resource
[0m19:34:27.793380 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=None, name=debug, idle-time=0.0010514259338378906s, acquire-count=1, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Checking idleness
[0m19:34:27.794299 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=None, name=debug, idle-time=0.0019004344940185547s, acquire-count=1, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Retrieving connection
[0m19:34:27.795052 [debug] [MainThread]: Using databricks connection "debug"
[0m19:34:27.795904 [debug] [MainThread]: On debug: select 1 as id
[0m19:34:27.796902 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:28.123958 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=01efc2f7-406d-1475-ace1-70040746cab3, name=debug, idle-time=7.62939453125e-06s, acquire-count=1, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Connection created
[0m19:34:28.125131 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f7-406d-1475-ace1-70040746cab3, command-id=Unknown) - Created cursor
[0m19:34:28.303199 [debug] [MainThread]: SQL status: OK in 0.510 seconds
[0m19:34:28.306065 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f7-406d-1475-ace1-70040746cab3, command-id=01efc2f7-4079-107d-93c6-28fd90377867) - Closing cursor
[0m19:34:28.307520 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140701873836752, session-id=01efc2f7-406d-1475-ace1-70040746cab3, name=debug, idle-time=1.33514404296875e-05s, acquire-count=0, language=None, thread-identifier=(9965, 140702724918144), compute-name=) - Released connection
[0m19:34:28.308416 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m19:34:28.309408 [info ] [MainThread]: [32mAll checks passed![0m
[0m19:34:28.313051 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 4.39404, "process_in_blocks": "16", "process_kernel_time": 0.521152, "process_mem_max_rss": "232648", "process_out_blocks": "48", "process_user_time": 4.472439}
[0m19:34:28.315330 [debug] [MainThread]: Command `dbt debug` succeeded at 19:34:28.314467 after 4.40 seconds
[0m19:34:28.317539 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:34:28.319348 [debug] [MainThread]: On debug: Close
[0m19:34:28.320484 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-406d-1475-ace1-70040746cab3) - Closing connection
[0m19:34:28.394784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e610d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e4396350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e4feb810>]}
[0m19:34:28.396013 [debug] [MainThread]: Flushing usage events
[0m19:34:29.380055 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:34:33.231628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0eac24890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0eaa68a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0eac25790>]}


============================== 19:34:33.235488 | 14ad2b02-b610-4fbd-906e-ae5b3f308b83 ==============================
[0m19:34:33.235488 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:34:33.236269 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/workspaces/flagstone-project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:34:33.246424 [info ] [MainThread]: dbt version: 1.9.1
[0m19:34:33.247507 [info ] [MainThread]: python version: 3.11.11
[0m19:34:33.248399 [info ] [MainThread]: python path: /home/vscode/.pyenv/versions/3.11.11/bin/python3.11
[0m19:34:33.249352 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35
[0m19:34:33.959806 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:34:33.960438 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:34:33.960874 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:34:34.715427 [info ] [MainThread]: Using profiles dir at .dbt/
[0m19:34:34.716020 [info ] [MainThread]: Using profiles.yml file at .dbt/profiles.yml
[0m19:34:34.716458 [info ] [MainThread]: Using dbt_project.yml file at /workspaces/flagstone-project/dbt_project.yml
[0m19:34:34.716889 [info ] [MainThread]: adapter type: databricks
[0m19:34:34.717231 [info ] [MainThread]: adapter version: 1.9.1
[0m19:34:34.831798 [info ] [MainThread]: Configuration:
[0m19:34:34.832425 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:34:34.832937 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:34:34.833351 [info ] [MainThread]: Required dependencies:
[0m19:34:34.833825 [debug] [MainThread]: Executing "git --help"
[0m19:34:34.835657 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:34:34.836089 [debug] [MainThread]: STDERR: "b''"
[0m19:34:34.836426 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:34:34.836850 [info ] [MainThread]: Connection:
[0m19:34:34.837470 [info ] [MainThread]:   host: adb-2822429466874508.8.azuredatabricks.net
[0m19:34:34.838052 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/cb126c8f6c99e71d
[0m19:34:34.838659 [info ] [MainThread]:   catalog: shop_data
[0m19:34:34.839332 [info ] [MainThread]:   schema: sales_data
[0m19:34:34.840470 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:34:35.129371 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Creating connection
[0m19:34:35.130240 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:34:35.130798 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=None, name=debug, idle-time=6.198883056640625e-06s, acquire-count=1, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Acquired connection on thread (10230, 140329177156480), using default compute resource
[0m19:34:35.131214 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=None, name=debug, idle-time=0.00043773651123046875s, acquire-count=1, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Checking idleness
[0m19:34:35.131585 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=None, name=debug, idle-time=0.0008141994476318359s, acquire-count=1, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Retrieving connection
[0m19:34:35.131903 [debug] [MainThread]: Using databricks connection "debug"
[0m19:34:35.132280 [debug] [MainThread]: On debug: select 1 as id
[0m19:34:35.132587 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:35.478173 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=01efc2f7-4587-15ab-bf6f-e07ed186e9be, name=debug, idle-time=9.775161743164062e-06s, acquire-count=1, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Connection created
[0m19:34:35.479357 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f7-4587-15ab-bf6f-e07ed186e9be, command-id=Unknown) - Created cursor
[0m19:34:35.763776 [debug] [MainThread]: SQL status: OK in 0.630 seconds
[0m19:34:35.765778 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01efc2f7-4587-15ab-bf6f-e07ed186e9be, command-id=01efc2f7-45a1-16fe-bff8-6700cea1d7bf) - Closing cursor
[0m19:34:35.766794 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140328444593040, session-id=01efc2f7-4587-15ab-bf6f-e07ed186e9be, name=debug, idle-time=7.3909759521484375e-06s, acquire-count=0, language=None, thread-identifier=(10230, 140329177156480), compute-name=) - Released connection
[0m19:34:35.767524 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m19:34:35.768300 [info ] [MainThread]: [32mAll checks passed![0m
[0m19:34:35.770274 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.6012015, "process_in_blocks": "0", "process_kernel_time": 0.366734, "process_mem_max_rss": "232680", "process_out_blocks": "24", "process_user_time": 3.930645}
[0m19:34:35.771153 [debug] [MainThread]: Command `dbt debug` succeeded at 19:34:35.770952 after 2.60 seconds
[0m19:34:35.771773 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:34:35.772401 [debug] [MainThread]: On debug: Close
[0m19:34:35.772974 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-4587-15ab-bf6f-e07ed186e9be) - Closing connection
[0m19:34:35.976214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0eac25910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0eac254d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0c021be50>]}
[0m19:34:35.977400 [debug] [MainThread]: Flushing usage events
[0m19:34:37.186418 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:34:43.190643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c52e7cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c52cda350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c5336d890>]}


============================== 19:34:43.194713 | 1c83fd5d-f8b6-46aa-a459-d5e6f36bc666 ==============================
[0m19:34:43.194713 [info ] [MainThread]: Running with dbt=1.9.1
[0m19:34:43.195582 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.dbt/', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/workspaces/flagstone-project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:34:43.968709 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:34:43.969446 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:34:43.969944 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:34:44.780280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c2b073150>]}
[0m19:34:44.850343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c53c174d0>]}
[0m19:34:44.851161 [info ] [MainThread]: Registered adapter: databricks=1.9.1
[0m19:34:45.198408 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m19:34:45.340505 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:45.341240 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:45.389932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c28139650>]}
[0m19:34:45.506418 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:34:45.508544 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:34:45.532152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c28482910>]}
[0m19:34:45.534278 [info ] [MainThread]: Found 3 models, 3 sources, 606 macros
[0m19:34:45.535490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c2839bbd0>]}
[0m19:34:45.538922 [info ] [MainThread]: 
[0m19:34:45.539663 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:45.540200 [info ] [MainThread]: 
[0m19:34:45.541436 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Creating connection
[0m19:34:45.542039 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:34:45.542700 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.344650268554688e-06s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Acquired connection on thread (10460, 140034571807616), using default compute resource
[0m19:34:45.556372 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=None, name=list_retail_data, idle-time=0s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Creating connection
[0m19:34:45.557075 [debug] [ThreadPool]: Acquiring new databricks connection 'list_retail_data'
[0m19:34:45.557638 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=None, name=list_retail_data, idle-time=6.198883056640625e-06s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Acquired connection on thread (10460, 140033715598912), using default compute resource
[0m19:34:45.558243 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=None, name=list_retail_data, idle-time=0.0006365776062011719s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:45.558712 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=None, name=list_retail_data, idle-time=0.0011315345764160156s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:45.559192 [debug] [ThreadPool]: Using databricks connection "list_retail_data"
[0m19:34:45.559668 [debug] [ThreadPool]: On list_retail_data: GetSchemas(database=retail_data, schema=None)
[0m19:34:45.560111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:45.864650 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data, idle-time=5.4836273193359375e-06s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Connection created
[0m19:34:45.865417 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=Unknown) - Created cursor
[0m19:34:46.453994 [debug] [ThreadPool]: SQL status: OK in 0.890 seconds
[0m19:34:46.455836 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=01efc2f7-4b76-1c03-b8b4-02f3db8a7eba) - Closing cursor
[0m19:34:46.456829 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data, idle-time=9.059906005859375e-06s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:46.459390 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data, idle-time=0.0025300979614257812s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:46.460470 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_retail_data, now list_retail_data_sales_data)
[0m19:34:46.461519 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.004592418670654297s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Reusing connection previously named list_retail_data
[0m19:34:46.462484 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.005589723587036133s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Acquired connection on thread (10460, 140033715598912), using default compute resource
[0m19:34:46.489975 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.03297257423400879s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:46.490958 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.034149169921875s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:46.491461 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.034681081771850586s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:46.491856 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.03508567810058594s, acquire-count=1, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:46.492257 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m19:34:46.492720 [debug] [ThreadPool]: Using databricks connection "list_retail_data_sales_data"
[0m19:34:46.493181 [debug] [ThreadPool]: On list_retail_data_sales_data: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "connection_name": "list_retail_data_sales_data"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'retail_data'
      and table_schema = 'sales_data'
    
  
[0m19:34:46.493677 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=Unknown) - Created cursor
[0m19:34:46.848659 [debug] [ThreadPool]: SQL status: OK in 0.350 seconds
[0m19:34:46.855611 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=01efc2f7-4bd1-1c95-a45a-926a511edb7a) - Closing cursor
[0m19:34:46.856840 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=7.152557373046875e-06s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:46.861444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c28618e90>]}
[0m19:34:46.862164 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=1.31953763961792s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Checking idleness
[0m19:34:46.862623 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=1.3200080394744873s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Retrieving connection
[0m19:34:46.863023 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=1.3204209804534912s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Checking idleness
[0m19:34:46.863430 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=1.3208274841308594s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Retrieving connection
[0m19:34:46.863823 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:34:46.864161 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:34:46.864680 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=5.9604644775390625e-06s, acquire-count=0, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Released connection
[0m19:34:46.869183 [debug] [Thread-1 (]: Began running node model.databricks.stg_customers
[0m19:34:46.870148 [info ] [Thread-1 (]: 1 of 3 START sql table model retail_data.sales_data.stg_customers .............. [RUN]
[0m19:34:46.871309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=list_retail_data_sales_data, idle-time=0.014469623565673828s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:46.871853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_retail_data_sales_data, now model.databricks.stg_customers)
[0m19:34:46.872507 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=0.0156402587890625s, acquire-count=0, language=None, thread-identifier=(10460, 140033715598912), compute-name=) - Reusing connection previously named list_retail_data_sales_data
[0m19:34:46.873155 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=0.01633453369140625s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Acquired connection on thread (10460, 140033715598912), using default compute resource for model '`retail_data`.`sales_data`.`stg_customers`'
[0m19:34:46.873907 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_customers
[0m19:34:46.891394 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_customers"
[0m19:34:46.893027 [debug] [Thread-1 (]: Began executing node model.databricks.stg_customers
[0m19:34:46.921728 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:34:47.022577 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_customers"
[0m19:34:47.024338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=0.16736984252929688s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:47.025198 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=0.1683351993560791s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:47.025831 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_customers"
[0m19:34:47.027696 [debug] [Thread-1 (]: On model.databricks.stg_customers: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_customers"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_customers`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS customer_id,
    first_name,
    last_name
FROM 
    `shop_data`.`sales_data`.`customers`
  
[0m19:34:47.028339 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=Unknown) - Created cursor
[0m19:34:50.021517 [debug] [Thread-1 (]: SQL status: OK in 2.990 seconds
[0m19:34:50.022999 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=01efc2f7-4c20-1c84-9d41-b652ff0ddc27) - Closing cursor
[0m19:34:50.062978 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=5.245208740234375e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:50.063785 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=3.5762786865234375e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:50.065434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c283f2550>]}
[0m19:34:50.066538 [info ] [Thread-1 (]: 1 of 3 OK created sql table model retail_data.sales_data.stg_customers ......... [[32mOK[0m in 3.19s]
[0m19:34:50.067543 [debug] [Thread-1 (]: Finished running node model.databricks.stg_customers
[0m19:34:50.068218 [debug] [Thread-1 (]: Began running node model.databricks.stg_orders
[0m19:34:50.068938 [info ] [Thread-1 (]: 2 of 3 START sql table model retail_data.sales_data.stg_orders ................. [RUN]
[0m19:34:50.069693 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_customers, idle-time=0.005937337875366211s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:50.070081 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_customers, now model.databricks.stg_orders)
[0m19:34:50.070960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=0.0071392059326171875s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Reusing connection previously named model.databricks.stg_customers
[0m19:34:50.071469 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=0.007684230804443359s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Acquired connection on thread (10460, 140033715598912), using default compute resource for model '`retail_data`.`sales_data`.`stg_orders`'
[0m19:34:50.072001 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_orders
[0m19:34:50.076346 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_orders"
[0m19:34:50.077489 [debug] [Thread-1 (]: Began executing node model.databricks.stg_orders
[0m19:34:50.080048 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:34:50.082254 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_orders"
[0m19:34:50.083558 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=0.019341707229614258s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:50.084718 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=0.020866870880126953s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:50.085252 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_orders"
[0m19:34:50.085856 [debug] [Thread-1 (]: On model.databricks.stg_orders: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_orders"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_orders`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS order_id,
    user_id AS customer_id,
    order_date,
    status
FROM 
    `shop_data`.`sales_data`.`orders`
  
[0m19:34:50.086517 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=Unknown) - Created cursor
[0m19:34:52.723000 [debug] [Thread-1 (]: SQL status: OK in 2.640 seconds
[0m19:34:52.724678 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=01efc2f7-4ddb-11fd-abe8-1ce86e3991ef) - Closing cursor
[0m19:34:52.726958 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=4.5299530029296875e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:52.727522 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=3.5762786865234375e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:52.728066 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c23e65250>]}
[0m19:34:52.728699 [info ] [Thread-1 (]: 2 of 3 OK created sql table model retail_data.sales_data.stg_orders ............ [[32mOK[0m in 2.66s]
[0m19:34:52.729368 [debug] [Thread-1 (]: Finished running node model.databricks.stg_orders
[0m19:34:52.729837 [debug] [Thread-1 (]: Began running node model.databricks.stg_payments
[0m19:34:52.730339 [info ] [Thread-1 (]: 3 of 3 START sql table model retail_data.sales_data.stg_payments ............... [RUN]
[0m19:34:52.731386 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_orders, idle-time=0.003786802291870117s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:52.731913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.databricks.stg_orders, now model.databricks.stg_payments)
[0m19:34:52.732384 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=0.0048716068267822266s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Reusing connection previously named model.databricks.stg_orders
[0m19:34:52.732811 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=0.0052568912506103516s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Acquired connection on thread (10460, 140033715598912), using default compute resource for model '`retail_data`.`sales_data`.`stg_payments`'
[0m19:34:52.733189 [debug] [Thread-1 (]: Began compiling node model.databricks.stg_payments
[0m19:34:52.736415 [debug] [Thread-1 (]: Writing injected SQL for node "model.databricks.stg_payments"
[0m19:34:52.737089 [debug] [Thread-1 (]: Began executing node model.databricks.stg_payments
[0m19:34:52.743118 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m19:34:52.745629 [debug] [Thread-1 (]: Writing runtime sql for node "model.databricks.stg_payments"
[0m19:34:52.746414 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=0.018873929977416992s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Checking idleness
[0m19:34:52.746831 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=0.019324302673339844s, acquire-count=1, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Retrieving connection
[0m19:34:52.747186 [debug] [Thread-1 (]: Using databricks connection "model.databricks.stg_payments"
[0m19:34:52.747798 [debug] [Thread-1 (]: On model.databricks.stg_payments: /* {"app": "dbt", "dbt_version": "1.9.1", "dbt_databricks_version": "1.9.1", "databricks_sql_connector_version": "3.7.0", "profile_name": "databricks", "target_name": "dev", "node_id": "model.databricks.stg_payments"} */

  
    
        create or replace table `retail_data`.`sales_data`.`stg_payments`
      
      using delta
      
      
      
      
      
      
      
      as
      SELECT 
    id AS payment_id,
    order_id,
    payment_method,
    amount
FROM 
    `shop_data`.`sales_data`.`payments`
  
[0m19:34:52.748423 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=Unknown) - Created cursor
[0m19:34:55.076311 [debug] [Thread-1 (]: SQL status: OK in 2.330 seconds
[0m19:34:55.078603 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, command-id=01efc2f7-4f5a-1649-9632-f24abf84de90) - Closing cursor
[0m19:34:55.082560 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=5.9604644775390625e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:55.083650 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=140033787007376, session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03, name=model.databricks.stg_payments, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(10460, 140033715598912), compute-name=) - Released connection
[0m19:34:55.084510 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c83fd5d-f8b6-46aa-a459-d5e6f36bc666', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c281203d0>]}
[0m19:34:55.085646 [info ] [Thread-1 (]: 3 of 3 OK created sql table model retail_data.sales_data.stg_payments .......... [[32mOK[0m in 2.35s]
[0m19:34:55.086814 [debug] [Thread-1 (]: Finished running node model.databricks.stg_payments
[0m19:34:55.089023 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.224439144134521s, acquire-count=0, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Checking idleness
[0m19:34:55.089616 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.22501254081726s, acquire-count=0, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Reusing connection previously named master
[0m19:34:55.090185 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.225581645965576s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Acquired connection on thread (10460, 140034571807616), using default compute resource
[0m19:34:55.090699 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.22613000869751s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Checking idleness
[0m19:34:55.091109 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=None, name=master, idle-time=8.226521253585815s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Retrieving connection
[0m19:34:55.091444 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:55.091991 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:56.952802 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=01efc2f7-519e-1382-b193-ab1642465600, name=master, idle-time=1.239776611328125e-05s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Connection created
[0m19:34:56.954066 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:34:56.955024 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=01efc2f7-519e-1382-b193-ab1642465600, name=master, idle-time=0.00235748291015625s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Checking idleness
[0m19:34:56.955939 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=01efc2f7-519e-1382-b193-ab1642465600, name=master, idle-time=0.0032854080200195312s, acquire-count=1, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Retrieving connection
[0m19:34:56.956573 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m19:34:56.957150 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m19:34:56.957771 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=140033787007632, session-id=01efc2f7-519e-1382-b193-ab1642465600, name=master, idle-time=5.7220458984375e-06s, acquire-count=0, language=None, thread-identifier=(10460, 140034571807616), compute-name=) - Released connection
[0m19:34:56.958490 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:56.959059 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:56.959803 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:34:56.960464 [debug] [MainThread]: On master: Close
[0m19:34:56.961110 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-519e-1382-b193-ab1642465600) - Closing connection
[0m19:34:57.033887 [debug] [MainThread]: Connection 'model.databricks.stg_payments' was properly closed.
[0m19:34:57.034988 [debug] [MainThread]: On model.databricks.stg_payments: ROLLBACK
[0m19:34:57.035858 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m19:34:57.036379 [debug] [MainThread]: On model.databricks.stg_payments: Close
[0m19:34:57.036879 [debug] [MainThread]: Databricks adapter: Connection(session-id=01efc2f7-4b6c-1dda-a11f-b4acef0ead03) - Closing connection
[0m19:34:57.191564 [info ] [MainThread]: 
[0m19:34:57.192669 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 11.65 seconds (11.65s).
[0m19:34:57.194556 [debug] [MainThread]: Command end result
[0m19:34:57.238484 [debug] [MainThread]: Wrote artifact WritableManifest to /workspaces/flagstone-project/target/manifest.json
[0m19:34:57.240844 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspaces/flagstone-project/target/semantic_manifest.json
[0m19:34:57.249533 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspaces/flagstone-project/target/run_results.json
[0m19:34:57.250044 [info ] [MainThread]: 
[0m19:34:57.250601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:57.251038 [info ] [MainThread]: 
[0m19:34:57.251563 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m19:34:57.253028 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.123693, "process_in_blocks": "0", "process_kernel_time": 0.43848, "process_mem_max_rss": "240948", "process_out_blocks": "2752", "process_user_time": 4.766092}
[0m19:34:57.253725 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:57.253565 after 14.12 seconds
[0m19:34:57.254133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c53280650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c569f5b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5c569f5f10>]}
[0m19:34:57.254552 [debug] [MainThread]: Flushing usage events
[0m19:34:59.895577 [debug] [MainThread]: An error was encountered while trying to flush usage events
